---
eip: 2315
title: Simple Subroutines for the EVM
description: This proposal introduces two opcodes to support simple subroutines.
status: Draft
type: Standards Track
category: Core
author: Greg Colvin <greg@colvin.org>, Martin Holst Swende (@holiman), Brooklyn Zelenka (@expede)
discussions-to: https://ethereum-magicians.org/t/eip-2315-simple-subroutines-for-the-evm/3941
created: 2019-10-17
requires: 3540, 3670, 3779, 4200
---

## Abstract

This proposal introduces two opcodes to support simple subroutines: `JUMPSUB` and `RETURNSUB`.

Taken together with other recent propoposals it provides an efficient, static, and safe control-flow facility.

## Motivation

The EVM does not provide subroutines as primitives.

Instead, calls can be synthesized by fetching and pushing the return address and subroutine address on the data stack and executing `JUMP` to the subroutine; returns can be synthesized by getting the return address to the top of the stack and jumping back to it.  These conventions cost gas and use stack slots unnecessarily.  And they create unnecessary complexity that is borne by the humans and programs writing, reading, and analyzing EVM code.  A `ROLL` operator could reduce the apparent complexity of the code - it would allow for the return address to be moved to the top of the stack with the remaining items on the stack being implicity shifted. But it would be an expensive operation with a dynamic gas cost.

As an alternative, we propose to provide for subroutines with two simple operations: `JUMPSUB` to call a subroutine and `RETURNSUB` to return from it.  Taken together with other recent propoposals they provide an efficient, static, and safe control-flow facility.

Efficient.  Substantial reductions in the complexity and the gas costs of calling and optimizing simple subroutines -- from 33% to as much as 52% savings in gas in the analysis below.

Static.  All possible jumps are known at contract creation time.

Safe.  Valid contracts will not halt with an exception unless they run out of gas or overflow stack while making a recursive subroutine call.

### History

Facilities to directly support subroutines are provided by all but one of the real and virtual machines we have programmed, including the Burroughs 5000, CDC 7600, IBM 360, DEC PDP 11 and VAX, Motorola 68000, Sun SPARC, a few generations of Intel silicon, ARM, UCSD p-machine, Sun JVM, Wasm, and the sole exception -- the EVM.  In whatever form, these operations provide for
* capturing the current context of execution,
* transferring control to a new context, and 
* returning to the original context
   * after possible further transfers of control
   * to some arbitrary depth.

The [concept](https://people.cs.clemson.edu/~mark/subroutines.html) goes back to [Turing's Automatic Computing Engine of 1946](http://www.alanturing.net/turing_archive/archive/p/p01/P01-001.html):
> ...
> We also wish to be able to arrange for the splitting up of operations into subsidiary operations.  This should be done in such a way that once we have written down how an operation is done we can use it as a subsidiary to any other operation.
> ...
> When we wish to start on a subsidiary operation we need only make a note of where we left off the major operation and then apply the first instruction of the subsidiary.  When the subsidiary is over we look up the note and continue with the major operation.  Each subsidiary operation can end with instructions for this recovery of the note. How is the burying and disinterring of the note to be done?  There are of course many ways.  One is to keep a list of these notes in one or more standard size delay lines, (1024) with the most recent last...

Turing's machine held data in delay lines made of mercury-filled crytals.  We have better hardware now, but the concept is simple and by now familiar: Turing's "subsidiary operations" are subroutines, and his "list of notes" is a stack of return addresses. 

We propose to follow Turing's lead in the design of our subroutine facility, as specified below.

### Subroutine Efficiency Analysis

We show here how these instructions can be used to reduce the complexity and gas costs of both ordinary subroutine calls and low-level optimizations compared to using `JUMP`.

We assume that `JUMPSUB` costs 5 gas, and `RETURNSUB` costs 8 gas.  We justify these costs below, but they do not make a large difference in this analysis, as much of the improvement is due to `PUSH` and `SWAP` operations that are no longer needed.

#### **Simple Subroutine Call**

Consider this example of calling a fairly minimal subroutine.

Subroutine call, using `JUMPSUB`:
```
TEST_SQUARE:
    jumpdest        ; 1 gas
    0x02            ; 3 gas
    jumpsub SQUARE  ; 5 gas
    returnsub       ; 3 gas

SQUARE:
    jumpdest        ; 1 gas
    dup1            ; 3 gas
    mul             ; 5 gas
    returnsub       ; 3 gas

Total 24 gas.
```
Subroutine call, using `JUMP`:
```
TEST_SQUARE:
    jumpdest        ; 1 gas
    RTN_SQUARE      ; 3 gas
    0x02            ; 3 gas
    SQUARE          ; 3 gas
    jump            ; 8 gas
RTN_SQUARE:
    jumpdest        ; 1 gas
    swap1           ; 3 gas
    jump            ; 8 gas

SQUARE:
    jumpdest        ; 1 gas
    dup1            ; 3 gas
    mul             ; 5 gas
    swap1           ; 3 gas
    jump            ; 8 gas

Total: 50 gas
```
Using `JUMPSUB` saves *50 - 24 = 26* gas versus using `JUMP` -- a *52%* performance improvement.

#### **Tail Call Optimization**

Of course in cases like this one we can optimize the tail call, so that the return from `SQUARE` actually returns from `TEST_SQUARE`.

Tail call optimization, using `RJUMP` and `RETURNSUB`:
```
TEST_SQUARE:
    jumpdest        ; 1 gas
    0x02            ; 3 gas
    rjump SQUARE    ; 3 gas

SQUARE:
    jumpdest        ; 1 gas
    dup1            ; 3 gas
    mul             ; 5 gas
    returnsub       ; 3 gas

Total: 19 gas
```
Tail call optimization, using `JUMP`:
```
TEST_SQUARE:
    jumpdest        ; 1 gas
    0x02            ; 3 gas
    SQUARE          ; 3 gas
    jump            ; 8 gas

SQUARE:
    jumpdest        ; 1 gas
    dup1            ; 3 gas
    mul             ; 5 gas
    swap1           ; 3 gas
    jump            ; 8 gas

Total: 33 gas
```
Using `JUMPSUB` versus `JUMP` saves *33 - 19 = 14* gas -- a *42%* performance improvement.

#### **Tail Call Elimination**

We can even take advantage of `SQUARE` just happening to directly follow `TEST_SQUARE` and just fall through rather than jump at all.

Tail call `elimination`, using JUMPSUB:
```
TEST_SQUARE:
    jumpdest        ; 1 gas
    0x02            ; 3 gas

SQUARE:
    jumpdest        ; 1 gas
    dup1            ; 3 gas
    mul             ; 5 gas
    returnsub       ; 3 gas

Total 16 gas.
```
Tail call elimination, using JUMP:
```
TEST_SQUARE:
    jumpdest        ; 1 gas
    0x02            ; 3 gas

SQUARE:
    jumpdest        ; 1 gas
    dup1            ; 3 gas
    mul             ; 5 gas
    swap1           ; 3 gas
    jump            ; 8 gas

Total: 24 gas
```
Using `RETURNSUB` versus `JUMP` saves _24 - 16 = 8_ gas -- a *33%* performance improvement.

####  **Call Using Data Stack**

We can also consider an alternative call mechanism -- call it `CALLSUB` -- that pushes its return address on the `data_stack`:
```
TEST_SQUARE:
    jumpdest        ; 1 gas
    0x02            ; 3 gas
    callsub SQUARE  ; 5 gas
    returnsub       ; 3 gas

SQUARE:
    jumpdest        ; 1 gas
    dup1            ; 3 gas
    mul             ; 5 gas
    swap1           ; 3 gas
    returncall      ; 3 gas
```
Total *28* gas, compared to *24* gas for the `JUMPSUB` version. Possibly more, as using the wide-integer _data stack_ is probably less efficient than using a stack of native integers.  Versus *50* gas for the `JUMP`version

So we can see that these instructions provide a simpler and more efficient subroutine mechanism than using `JUMP`.

_Note comprising large subroutines rather than being factored into smaller ones._

## Specification

To support calls and returns we specifiy an EVM `return stack` in addition to the existing `data stack`. The `return stack`, like the `data stack`, is limited to `1024` items. This stack supports two new instructions for subroutines.

### Instructions

#### `JUMPSUB (0x5e) jmpdest`

> Transfers control to a subroutine.
>
> 1. Decode the `jmpdest` from the immediate data.  The data is encoded as two bytes, MSB-first.
> 2. Push `jmpdest + 1` on the `return stack`.
> 3. Set `PC` to `jmpdest`.
>
>  The cost is _low_.
>  
> * _pushes one item on the `return stack`_

#### `RETURNSUB (0x5f)`

> Returns control to the caller of a subroutine.
> 
> 1.  Pop `PC` off the `return stack`.
>
> The cost is _verylow_.
>
> * _pops one item off the `return stack`_

_Notes:_
* _If a resulting `PC` to be executed is beyond the last instruction then the opcode is implicitly a `STOP`, which is not an error._
* _Values popped off the `return stack` do not need to be validated, since they are alterable only by `JUMPSUB` and `RETURNSUB`._ 
* _The description above lays out the semantics of these instructions in terms of a `return stack`.  But the actual state of the `return stack` is not observable by EVM code or consensus-critical to the protocol.  (For example, a node implementer may code `JUMPSUB` to unobservably push `PC` on the `return stack` rather than `PC + 1`, which is allowed so long as `RETURNSUB` observably returns control to the `PC + 1` location.)_
* _The `return stack` is the functional equivalent of Turing's "delay line"._

The _low_ cost of `JUMPSUB` versus `JUMP` is justified by needing only to push the return address on the `return stack` and decode the immediate two byte destination to the `PC`, all using native arithmetric, versus using the data stack with emulated 256-bit instructions.

The _verylow_ cost of `RETURNSUB` is justified by needing only to pop the `return stack` into the `PC`.  Benchmarking will be needed to tell if the costs are well-balanced.

### Validity

We define safety here as avoiding exceptional halting states, as defined in the Yellow Paper.  We can always detect three of these states at *validation time*:
* Insufficient stack items
* Invalid jump destination
* Invalid instruction

Two remaining states we must test for at _runtime_:

* Valid contracts will not halt with an exception unless they
   * run out of gas or
   * overflow stack while making a recursive subroutine call.

Attempts to create invalid contracts will fail.

#### Dependencies

Code validation depends on a few other EIPs.

[EIP-3540](./eip-3540.md) -- Introduces Ethereum Object Format, distinguishing _code_ from _data_, _initcode_ from code, and _validation time_ from _runtime_.  Validation of the format is specified. 

[EIP-3670](./eip-3670.md) -- Introduces validation for well-formed code with valid instructions and pushdata.

[EIP-4200](./eip-4200.md) -- Introduces static relative jumps with immediate jumdpdata.  Validation given below.

Alternatives:
* [EIP-3779](./eip-3779.md) -- Introduces validation for the safe use of `JUMP` and `JUMPI` instructions.
* Deprecate `JUMP` and `JUMPI`.

#### Constraints on Valid Code

> This section extends the validation rules given in EIP-3540, EIP-3670, EIP-3779, and EIP-4200.)

The Yellow Paper has the `stack pointer` (`SP`) pointing just past the top item on the `data stack`.   We define the _available items_ as the number of stack items between the current `SP` and the `SP` at the begining of the most recent basic block.

1. Every `JUMPSUB` addresses a valid `JUMPDEST`.
2. The number of items on the `data stack` is
   * always positive, and
   * at most 1024.
3. The _available items_ on the `data stack` are
   * the same on every path through a `code` offset.
5. The number of items on the `return stack` is
   * at most 1024.

Taken together, these rules allow for code to be validated by traversing the control-flow graph, following each edge only once. 

_Note that this specification is entirely semantic.  It imposes no further syntax on code._

## Rationale

There are at least two designs for a subroutine facility.

We have chosen Turing's design, as have Forth, the JVM, Wasm, and others. We keep return addresses on a dedicated FIFO`return stack`.  The instruction to call a subroutine will
* push the return address onto the `return stack` and
* jump to the first instruction of the subroutine.

The instruction to return from a subroutine will
* jump to the address popped off of the`return stack`.

We give an example of alternative design above, using a single `data stack` in RAM for both data and return addresses. This design is used by most of the register machines we have programmed.  The instruction to call a subroutine will
* push the return address on the `data stack` and
* jump to the first instruction of the subroutine.

The instruction to return from a subroutine will
* jump to the addess popped off of the `data stack`.
_Note that the program must first ensure that the return address is the first element on the stack._

We prefer Turing's design for a few reasons.
* It maintains a clear separation between calculation and flow of control.
* It improves performance by
  * using native arithmetic rather than 256-bit EVM instructions for the return address,
  * not needing a `data stack` slot for the return address,
  * and not needing to move parameters and return values around the return address.
* It has a 75-year history of working well, especially for stack machines.

## Backwards Compatibility

These changes affect the semantics of existing EVM code.  These changes are compatible with the restricted forms of `JUMP` and `JUMPI` specified by [EIP-3779](./eip-3779.md)  -- contracts following all of the rules given there and here will be valid.

## Reference Implementation 

### Validation Algorithm 

> This section specifies an algorithm for ensuring _code validity_. An equivalent algorithm must be run at creation time.  We assume that the validation dependencies above have already been checked, although in practice the algorithms can be merged.

The following is a pseudo-Go implementation of an algorithm for predicating contract validity.  This algorithm is a symbolic execution of the program that recursively traverses the _code_, following its control flow and stack use and checking for violations of the rules above.

This algorithm runs in time equal to `O(vertices + edges)` in the program's control-flow graph, where edges represent control flow and the vertices represent _basic blocks_ â€“ thus the algorithm takes time proportional to the size of the _code_.

For simplicity's sake we assume that _jumpdest analysis_ has been done and that we have a few helper functions.
* `valid_destination(pc)` is false if `pc` points at immediate data
* `is_jumpdest(pc)` is true if `pc` points at `JUMPDEST`.
* `imm_data(pc)` returns immediate data for an instruction.
* `advance_pc()` advances the pc,  skipping any immediate data.
* `n_items_removed(pc)` returns the number of items removed from the `data_stack` by an instruction.
* `n_items_added(pc)` returns the number of items added to the `data_stack` by an instruction.
```
var code        [code_len]byte
var avail_items [code_len]int
var return_stack[] = { -1 }
    
func validate(pc := 0, sp := 0, bp := 0) (int, bool {

   for pc < code_len {
       if !valid_instruction(pc) {
         return false
      }
  
      // check for overflow
      if (sp > 1024) {
         return false
      }

      // if data stack depth for `pc` is non-zero
      //    we have been here before
      //    so return to break cycle
      if avail_items[pc] != 0 {

          // invalid if available items not the same
          if avail_items[pc] != sp - bp {
             return false
          }
          return true
      }
      avail_items[pc] = sp - bp
      if avail_items[pc] < 0 {
         return false
      }

      // successful termination
      case STOP:
         return true
      case RETURN:
         return true
      case SUICIDE:
         return true

      case JUMPSUB:

         // check for valid destination
         jumpdest = imm_data(pc)
         if !valid_jumpdest(jumpdest) {
            return false
         }

         // will enter basic block at destination
         bp = sp

         // reset pc to destination of jump
         return_stack[sp--] = pc + 1
         pc = jumpdest

      case RETURNSUB:
      
         // will enter basic block at destination
         bp = sp

         // check for valid return destination
         pc = return_stack[sp++]
         if !code[pc - 1] == JUMPSUB {
            return false
         }
      
      case RJUMP:
      
         // will enter basic block at destination
         bp = sp

         // reset pc to destination of jump
         pc += imm_data(pc)

      case RJUMPI:
      
         // will enter basic block at destination
         bp = sp

         // recurse to validate true side of conditional
         jumpdest := pc + imm_data(PC)
         if !valid_destination(jumpdest) {
            return false
         }
         if !validate(jumpdest, sp, bp) {
            return false
         }

         // advance to validate false side of conditional
         pc = advance_pc(pc)
          
      default:
         pc = advance_pc(pc)

         // apply other instructions to stack pointer
         sp -= remove_items(pc)
         sp -= add_items(pc)
         if sp > 
      }
   }

   // successful termination
   return true
}
```

## Security Considerations

These changes do introduce new flow control instructions, so any software which does static/dynamic analysis of EVM code needs to be modified accordingly. The `JUMPSUB` semantics are similar to `JUMP` whereas the `RETURNSUB` instruction is different, since it can 'land' on any opcode (but the possible destinations can be statically inferred).

The validation algorithm mu st run in time and space near-linear in the size of its input so that it can be charged appropriate gas to avoid DoS attack.

## Copyright
Copyright and related rights waived via [CC0](https://creativecommons.org/publicdomain/zero/1.0/).

